{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import collections\n",
    "import enum\n",
    "import math\n",
    "import pathlib\n",
    "import typing\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from solution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path.cwd()\n",
    "model_dir = pathlib.Path.cwd()\n",
    "output_dir = pathlib.Path.cwd()\n",
    "\n",
    "# Load training data\n",
    "train_xs = torch.from_numpy(np.load(data_dir / \"train_xs.npz\")[\"train_xs\"])\n",
    "raw_train_meta = np.load(data_dir / \"train_ys.npz\")\n",
    "train_ys = torch.from_numpy(raw_train_meta[\"train_ys\"])\n",
    "train_is_snow = torch.from_numpy(raw_train_meta[\"train_is_snow\"])\n",
    "train_is_cloud = torch.from_numpy(raw_train_meta[\"train_is_cloud\"])\n",
    "dataset_train = torch.utils.data.TensorDataset(train_xs, train_is_snow, train_is_cloud, train_ys)\n",
    "\n",
    "# Load validation data\n",
    "val_xs = torch.from_numpy(np.load(data_dir / \"val_xs.npz\")[\"val_xs\"])\n",
    "raw_val_meta = np.load(data_dir / \"val_ys.npz\")\n",
    "val_ys = torch.from_numpy(raw_val_meta[\"val_ys\"])\n",
    "val_is_snow = torch.from_numpy(raw_val_meta[\"val_is_snow\"])\n",
    "val_is_cloud = torch.from_numpy(raw_val_meta[\"val_is_cloud\"])\n",
    "dataset_val = torch.utils.data.TensorDataset(val_xs, val_is_snow, val_is_cloud, val_ys)\n",
    "\n",
    "# Fix all randomness\n",
    "setup_seeds()\n",
    "\n",
    "# Build and run the actual solution\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "swag = SWAGInference(\n",
    "    train_xs=dataset_train.tensors[0],\n",
    "    model_dir=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained MAP weights from c:\\Users\\Jeremias\\Documents\\ETH\\Semester7\\PAI\\task2\\map_weights.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running gradient descent for SWA:  53%|█████▎    | 16/30 [08:31<07:27, 31.95s/it, lr=0.045, avg. epoch loss=0.462, avg. epoch accuracy=0.837]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jeremias\\Documents\\ETH\\Semester7\\PAI\\task2\\task2nb.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jeremias/Documents/ETH/Semester7/PAI/task2/task2nb.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m swag\u001b[39m.\u001b[39;49mfit(train_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jeremias/Documents/ETH/Semester7/PAI/task2/task2nb.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m swag\u001b[39m.\u001b[39mcalibrate(dataset_val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jeremias/Documents/ETH/Semester7/PAI/task2/task2nb.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mfork_rng():\n",
      "File \u001b[1;32mc:\\Users\\Jeremias\\Documents\\ETH\\Semester7\\PAI\\task2\\solution.py:416\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_map(loader)\n\u001b[0;32m    415\u001b[0m \u001b[39m# SWAG\u001b[39;00m\n\u001b[1;32m--> 416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference_mode \u001b[39min\u001b[39;00m (InferenceMode\u001b[39m.\u001b[39mSWAG_DIAGONAL, InferenceMode\u001b[39m.\u001b[39mSWAG_FULL):\n\u001b[0;32m    417\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_swag(loader)\n",
      "File \u001b[1;32mc:\\Users\\Jeremias\\Documents\\ETH\\Semester7\\PAI\\task2\\solution.py:244\u001b[0m, in \u001b[0;36mfit_swag\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39m# Calculate cumulative average training loss and accuracy\u001b[39;00m\n\u001b[0;32m    241\u001b[0m average_loss \u001b[39m=\u001b[39m (batch_xs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m batch_loss\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m num_samples_processed \u001b[39m*\u001b[39m average_loss) \u001b[39m/\u001b[39m (\n\u001b[0;32m    242\u001b[0m     num_samples_processed \u001b[39m+\u001b[39m batch_xs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m    243\u001b[0m )\n\u001b[1;32m--> 244\u001b[0m average_accuracy \u001b[39m=\u001b[39m (\n\u001b[0;32m    245\u001b[0m     torch\u001b[39m.\u001b[39msum(pred_ys\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m batch_ys)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    246\u001b[0m     \u001b[39m+\u001b[39m num_samples_processed \u001b[39m*\u001b[39m average_accuracy\n\u001b[0;32m    247\u001b[0m ) \u001b[39m/\u001b[39m (num_samples_processed \u001b[39m+\u001b[39m batch_xs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[0;32m    248\u001b[0m num_samples_processed \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_xs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m    249\u001b[0m pbar_dict[\u001b[39m\"\u001b[39m\u001b[39mavg. epoch loss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m average_loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "swag.fit(train_loader)\n",
    "swag.calibrate(dataset_val)\n",
    "\n",
    "with torch.random.fork_rng():\n",
    "    evaluate(swag, dataset_val, EXTENDED_EVALUATION, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jeremias\\Documents\\ETH\\Semester7\\PAI\\task2\\task2nb.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jeremias/Documents/ETH/Semester7/PAI/task2/task2nb.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m],[\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m]])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jeremias/Documents/ETH/Semester7/PAI/task2/task2nb.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m np\u001b[39m.\u001b[39;49msoftmax(a, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jeremias\\AppData\\Local\\conda\\conda\\envs\\pai\\lib\\site-packages\\numpy\\__init__.py:284\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'softmax'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
